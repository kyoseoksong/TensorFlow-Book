{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf # 관련 라이브러리를 불러오고 하이퍼파라미터를 초기화합니다\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 1000\n",
    "reg_lambda = 0.\n",
    "\n",
    "x_dataset = np.linspace(-1, 1, 100) # 가짜 데이터셋인 y = x2 을 생성합니다\n",
    "\n",
    "num_coeffs = 9\n",
    "y_dataset_params = [0.] * num_coeffs\n",
    "y_dataset_params[2] = 1\n",
    "y_dataset = 0\n",
    "for i in range(num_coeffs):\n",
    "    y_dataset += y_dataset_params[i] * np.power(x_dataset, i)\n",
    "y_dataset += np.random.randn(*x_dataset.shape) * 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(x_dataset, y_dataset, ratio): # 코드 3.4에서 작성해 둔 함수를 가져와서 이용합니다\n",
    "    arr = np.arange(x_dataset.size)\n",
    "    np.random.shuffle(arr)\n",
    "    num_train = int(ratio * x_dataset.size)\n",
    "    x_train = x_dataset[arr[0:num_train]]\n",
    "    x_test = x_dataset[arr[num_train:x_dataset.size]]\n",
    "    y_train = y_dataset[arr[0:num_train]]\n",
    "    y_test = y_dataset[arr[num_train:x_dataset.size]]\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "(x_train, x_test, y_train, y_test) = split_dataset(x_dataset, y_dataset, 0.7) # 코드 3.4에서 만들어둔 함수를 호출하여 데이터셋을 학습 70%, 테스트 30%로 분리합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32) # 입력/출력 플레이스홀더를 설정합니다\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "def model(X, w): # 모델을 정의합니다\n",
    "    terms = []\n",
    "    for i in range(num_coeffs):\n",
    "        term = tf.multiply(w[i], tf.pow(X, i))\n",
    "        terms.append(term)\n",
    "    return tf.add_n(terms)\n",
    "\n",
    "w = tf.Variable([0.] * num_coeffs, name=\"parameters\") # 정규화된 비용 함수를 정의합니다\n",
    "y_model = model(X, w)\n",
    "cost = tf.div(tf.add(tf.reduce_sum(tf.square(Y-y_model)), \n",
    "                     tf.multiply(reg_lambda, tf.reduce_sum(tf.square(w)))),\n",
    "              2*x_train.size)\n",
    "train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg lambda 0.0\n",
      "final cost 0.023054438\n",
      "reg lambda 0.010101010101010102\n",
      "final cost 0.018039538\n",
      "reg lambda 0.020202020202020204\n",
      "final cost 0.017414615\n",
      "reg lambda 0.030303030303030304\n",
      "final cost 0.017644951\n",
      "reg lambda 0.04040404040404041\n",
      "final cost 0.01827447\n",
      "reg lambda 0.05050505050505051\n",
      "final cost 0.019142482\n",
      "reg lambda 0.06060606060606061\n",
      "final cost 0.02013635\n",
      "reg lambda 0.07070707070707072\n",
      "final cost 0.021174526\n",
      "reg lambda 0.08080808080808081\n",
      "final cost 0.022202263\n",
      "reg lambda 0.09090909090909091\n",
      "final cost 0.02318563\n",
      "reg lambda 0.10101010101010102\n",
      "final cost 0.024105562\n",
      "reg lambda 0.11111111111111112\n",
      "final cost 0.024953071\n",
      "reg lambda 0.12121212121212122\n",
      "final cost 0.02572572\n",
      "reg lambda 0.13131313131313133\n",
      "final cost 0.026425075\n",
      "reg lambda 0.14141414141414144\n",
      "final cost 0.027055057\n",
      "reg lambda 0.15151515151515152\n",
      "final cost 0.027620904\n",
      "reg lambda 0.16161616161616163\n",
      "final cost 0.028128207\n",
      "reg lambda 0.17171717171717174\n",
      "final cost 0.028582832\n",
      "reg lambda 0.18181818181818182\n",
      "final cost 0.02899022\n",
      "reg lambda 0.19191919191919193\n",
      "final cost 0.029355522\n",
      "reg lambda 0.20202020202020204\n",
      "final cost 0.029683467\n",
      "reg lambda 0.21212121212121213\n",
      "final cost 0.02997833\n",
      "reg lambda 0.22222222222222224\n",
      "final cost 0.030243734\n",
      "reg lambda 0.23232323232323235\n",
      "final cost 0.03048315\n",
      "reg lambda 0.24242424242424243\n",
      "final cost 0.030699454\n",
      "reg lambda 0.25252525252525254\n",
      "final cost 0.030895175\n",
      "reg lambda 0.26262626262626265\n",
      "final cost 0.03107265\n",
      "reg lambda 0.27272727272727276\n",
      "final cost 0.031233737\n",
      "reg lambda 0.2828282828282829\n",
      "final cost 0.031380005\n",
      "reg lambda 0.29292929292929293\n",
      "final cost 0.031513203\n",
      "reg lambda 0.30303030303030304\n",
      "final cost 0.03163462\n",
      "reg lambda 0.31313131313131315\n",
      "final cost 0.031744983\n",
      "reg lambda 0.32323232323232326\n",
      "final cost 0.031846028\n",
      "reg lambda 0.33333333333333337\n",
      "final cost 0.031937946\n",
      "reg lambda 0.3434343434343435\n",
      "final cost 0.03202206\n",
      "reg lambda 0.3535353535353536\n",
      "final cost 0.03209833\n",
      "reg lambda 0.36363636363636365\n",
      "final cost 0.032167673\n",
      "reg lambda 0.37373737373737376\n",
      "final cost 0.03223073\n",
      "reg lambda 0.38383838383838387\n",
      "final cost 0.03228794\n",
      "reg lambda 0.393939393939394\n",
      "final cost 0.032339785\n",
      "reg lambda 0.4040404040404041\n",
      "final cost 0.032386493\n",
      "reg lambda 0.4141414141414142\n",
      "final cost 0.032428723\n",
      "reg lambda 0.42424242424242425\n",
      "final cost 0.0324663\n",
      "reg lambda 0.43434343434343436\n",
      "final cost 0.03250029\n",
      "reg lambda 0.4444444444444445\n",
      "final cost 0.03253014\n",
      "reg lambda 0.4545454545454546\n",
      "final cost 0.032556433\n",
      "reg lambda 0.4646464646464647\n",
      "final cost 0.0325796\n",
      "reg lambda 0.4747474747474748\n",
      "final cost 0.032599647\n",
      "reg lambda 0.48484848484848486\n",
      "final cost 0.032615922\n",
      "reg lambda 0.494949494949495\n",
      "final cost 0.03262991\n",
      "reg lambda 0.5050505050505051\n",
      "final cost 0.032641698\n",
      "reg lambda 0.5151515151515152\n",
      "final cost 0.032651406\n",
      "reg lambda 0.5252525252525253\n",
      "final cost 0.03265815\n",
      "reg lambda 0.5353535353535354\n",
      "final cost 0.032662027\n",
      "reg lambda 0.5454545454545455\n",
      "final cost 0.03266451\n",
      "reg lambda 0.5555555555555556\n",
      "final cost 0.032665163\n",
      "reg lambda 0.5656565656565657\n",
      "final cost 0.032663725\n",
      "reg lambda 0.5757575757575758\n",
      "final cost 0.032661125\n",
      "reg lambda 0.5858585858585859\n",
      "final cost 0.032657117\n",
      "reg lambda 0.595959595959596\n",
      "final cost 0.03265105\n",
      "reg lambda 0.6060606060606061\n",
      "final cost 0.032644127\n",
      "reg lambda 0.6161616161616162\n",
      "final cost 0.032635607\n",
      "reg lambda 0.6262626262626263\n",
      "final cost 0.03262482\n",
      "reg lambda 0.6363636363636365\n",
      "final cost 0.032613825\n",
      "reg lambda 0.6464646464646465\n",
      "final cost 0.03260084\n",
      "reg lambda 0.6565656565656566\n",
      "final cost 0.032587737\n",
      "reg lambda 0.6666666666666667\n",
      "final cost 0.03257322\n",
      "reg lambda 0.6767676767676768\n",
      "final cost 0.032558255\n",
      "reg lambda 0.686868686868687\n",
      "final cost 0.032542292\n",
      "reg lambda 0.696969696969697\n",
      "final cost 0.032525375\n",
      "reg lambda 0.7070707070707072\n",
      "final cost 0.0325087\n",
      "reg lambda 0.7171717171717172\n",
      "final cost 0.032490015\n",
      "reg lambda 0.7272727272727273\n",
      "final cost 0.032471873\n",
      "reg lambda 0.7373737373737375\n",
      "final cost 0.032452676\n",
      "reg lambda 0.7474747474747475\n",
      "final cost 0.032433107\n",
      "reg lambda 0.7575757575757577\n",
      "final cost 0.03241247\n",
      "reg lambda 0.7676767676767677\n",
      "final cost 0.03239244\n",
      "reg lambda 0.7777777777777778\n",
      "final cost 0.032370884\n",
      "reg lambda 0.787878787878788\n",
      "final cost 0.03234948\n",
      "reg lambda 0.797979797979798\n",
      "final cost 0.03232763\n",
      "reg lambda 0.8080808080808082\n",
      "final cost 0.032305848\n",
      "reg lambda 0.8181818181818182\n",
      "final cost 0.03228354\n",
      "reg lambda 0.8282828282828284\n",
      "final cost 0.032260243\n",
      "reg lambda 0.8383838383838385\n",
      "final cost 0.032238122\n",
      "reg lambda 0.8484848484848485\n",
      "final cost 0.032214373\n",
      "reg lambda 0.8585858585858587\n",
      "final cost 0.03219149\n",
      "reg lambda 0.8686868686868687\n",
      "final cost 0.03216676\n",
      "reg lambda 0.8787878787878789\n",
      "final cost 0.0321431\n",
      "reg lambda 0.888888888888889\n",
      "final cost 0.03211922\n",
      "reg lambda 0.8989898989898991\n",
      "final cost 0.032094862\n",
      "reg lambda 0.9090909090909092\n",
      "final cost 0.03207142\n",
      "reg lambda 0.9191919191919192\n",
      "final cost 0.032046247\n",
      "reg lambda 0.9292929292929294\n",
      "final cost 0.032021888\n",
      "reg lambda 0.9393939393939394\n",
      "final cost 0.031997606\n",
      "reg lambda 0.9494949494949496\n",
      "final cost 0.031972848\n",
      "reg lambda 0.9595959595959597\n",
      "final cost 0.031949207\n",
      "reg lambda 0.9696969696969697\n",
      "final cost 0.03192545\n",
      "reg lambda 0.9797979797979799\n",
      "final cost 0.031900354\n",
      "reg lambda 0.98989898989899\n",
      "final cost 0.031875763\n",
      "reg lambda 1.0\n",
      "final cost 0.031851362\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session() # 세션을 설정합니다\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for reg_lambda in np.linspace(0, 1, 100): # 다양한 정규화 파라미터를 시도해 봅니다\n",
    "    for epoch in range(training_epochs):\n",
    "        sess.run(train_op, feed_dict={X: x_train, Y: y_train})\n",
    "    final_cost = sess.run(cost, feed_dict={X: x_test, Y: y_test})\n",
    "    print('reg lambda', reg_lambda)\n",
    "    print('final cost', final_cost)\n",
    "\n",
    "sess.close() # 세션을 닫습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
